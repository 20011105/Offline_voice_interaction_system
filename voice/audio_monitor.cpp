// audio_monitor.cpp
// éŸ³é¢‘ç›‘æ§å’Œè¯­éŸ³è½¬æ–‡æœ¬ç¨‹åº (C++ç‰ˆæœ¬)
// åŠŸèƒ½ï¼š
// 1. æ£€æµ‹éŸ³é¢‘è®¾å¤‡
// 2. å®æ—¶ç›‘å¬éŸ³é¢‘è¾“å…¥
// 3. ä½¿ç”¨VADæ£€æµ‹è¯­éŸ³æ´»åŠ¨
// 4. å°†è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬å¹¶æ‰“å°åˆ°ç»ˆç«¯

// audio_monitor.cpp (æœ€ç»ˆä¿®æ­£ç‰ˆ)

#include "audio_monitor.h"
#include "globals.h"
#include <iostream>
#include <fstream>
#include <thread>
#include <chrono>
#include <signal.h>

// ä½¿ç”¨ using namespace æ¥ç®€åŒ–ä»£ç 
using namespace sherpa_onnx::cxx;

AudioMonitor::AudioMonitor(const std::string& model_dir, const std::string& vad_model_path)
    : model_dir_("/home/lx/æ¡Œé¢/Voice/LLM_Voice_Flow-master/voice/models/sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16"),
      vad_model_path_(vad_model_path),
      sample_rate_(16000),
      samples_per_read_(static_cast<int>(0.1 * 16000)),
      is_speech_detected_(false)
{
    init_models();
}

AudioMonitor::~AudioMonitor() {
    if (audio_stream_) {
        if (Pa_IsStreamActive(audio_stream_)) {
            Pa_StopStream(audio_stream_);
        }
        Pa_CloseStream(audio_stream_);
    }
}

void AudioMonitor::init_models() {
    std::cout << "æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹..." << std::endl;
    init_vad();
    init_asr();
    std::cout << "æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼" << std::endl;
}

void AudioMonitor::init_vad() {
    if (vad_model_path_.empty()) {
        vad_model_path_ = download_vad_model();
    }
    VadModelConfig config;
    config.silero_vad.model = vad_model_path_;
    config.sample_rate = sample_rate_;
    config.silero_vad.threshold = 0.5;
    config.silero_vad.min_speech_duration = 0.25;
    config.silero_vad.min_silence_duration = 0.5;
    config.silero_vad.window_size = 512;

    // 1. ä¿®æ­£ï¼šä¸º Create æ–¹æ³•æä¾›ç¬¬äºŒä¸ªå‚æ•° (ç¼“å†²åŒºå¤§å°ï¼Œå•ä½ï¼šç§’)
    vad_ = std::make_unique<VoiceActivityDetector>(
        VoiceActivityDetector::Create(config, 30.0f)
    );
    std::cout << "VADæ¨¡å‹åˆå§‹åŒ–å®Œæˆ" << std::endl;
}

void AudioMonitor::init_asr() {
    OnlineRecognizerConfig config;
    config.model_config.transducer.encoder = model_dir_ + "/encoder-epoch-99-avg-1.int8.onnx";
    config.model_config.transducer.decoder = model_dir_ + "/decoder-epoch-99-avg-1.int8.onnx";
    config.model_config.transducer.joiner = model_dir_ + "/joiner-epoch-99-avg-1.int8.onnx";
    config.model_config.tokens = model_dir_ + "/tokens.txt";

    if (!file_exists(config.model_config.transducer.encoder)) {
        std::cout << "æœªæ‰¾åˆ°int8é‡åŒ–æ¨¡å‹ï¼Œå°è¯•ä½¿ç”¨fp32æ¨¡å‹..." << std::endl;
        config.model_config.transducer.encoder = model_dir_ + "/encoder-epoch-99-avg-1.onnx";
        config.model_config.transducer.decoder = model_dir_ + "/decoder-epoch-99-avg-1.onnx";
        config.model_config.transducer.joiner = model_dir_ + "/joiner-epoch-99-avg-1.onnx";
    } else {
        std::cout << "ä½¿ç”¨int8é‡åŒ–æ¨¡å‹ä»¥æé«˜æ€§èƒ½" << std::endl;
    }
    
    config.model_config.num_threads = 4;
    
    // 2. ä¿®æ­£ï¼šä½¿ç”¨ Create è¿”å›çš„å¯¹è±¡æ¥æ„é€  unique_ptr
    recognizer_ = std::make_unique<OnlineRecognizer>(
        OnlineRecognizer::Create(config)
    );
    stream_ = std::make_unique<OnlineStream>(
        recognizer_->CreateStream()
    );
    std::cout << "ASRæ¨¡å‹åˆå§‹åŒ–å®Œæˆ" << std::endl;
}

std::string AudioMonitor::download_vad_model() {
    std::string vad_model_path = "/home/lx/æ¡Œé¢/Voice/LLM_Voice_Flow-master/voice/models/sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16/silero_vad.onnx";
    if (!file_exists(vad_model_path)) {
        std::cout << "æ­£åœ¨ä¸‹è½½VADæ¨¡å‹..." << std::endl;
        std::string cmd = "wget -q -O " + vad_model_path + " https://github.com/snakers4/silero-vad/raw/master/files/silero_vad.onnx";
        system(cmd.c_str());
        std::cout << "VADæ¨¡å‹ä¸‹è½½å®Œæˆ" << std::endl;
    }
    return vad_model_path;
}

bool AudioMonitor::file_exists(const std::string& path) {
    std::ifstream file(path);
    return file.good();
}

std::vector<AudioDevice> AudioMonitor::list_audio_devices() {
    std::vector<AudioDevice> devices;
    int num_devices = Pa_GetDeviceCount();
    std::cout << "\n=== å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡ ===" << std::endl;
    for (int i = 0; i < num_devices; ++i) {
        const PaDeviceInfo* device_info = Pa_GetDeviceInfo(i);
        if (device_info && device_info->maxInputChannels > 0) {
            AudioDevice device;
            device.index = i;
            device.name = device_info->name;
            device.is_input = true;
            devices.push_back(device);
            std::cout << i << ": " << device.name << " (è¾“å…¥)" << std::endl;
        }
    }
    int default_input = Pa_GetDefaultInputDevice();
    if (default_input != paNoDevice) {
        const PaDeviceInfo* default_info = Pa_GetDeviceInfo(default_input);
        if (default_info) {
            std::cout << "\né»˜è®¤è¾“å…¥è®¾å¤‡: " << default_info->name << " (ç´¢å¼• " << default_input << ")" << std::endl;
        }
    }
    return devices;
}

void AudioMonitor::start_monitoring(int device_idx, const std::function<void(const std::string&)>& callback) {
    PaError err = Pa_Initialize();
    if (err != paNoError) {
        std::cerr << "!!! PortAudio åˆå§‹åŒ–å¤±è´¥: " << Pa_GetErrorText(err) << std::endl;
        return;
    }

    auto devices = list_audio_devices();
    if (devices.empty()) {
        std::cerr << "é”™è¯¯ï¼šæœªæ‰¾åˆ°ä»»ä½•éŸ³é¢‘è¾“å…¥è®¾å¤‡ã€‚" << std::endl;
        Pa_Terminate();
        return;
    }

    if (device_idx == -1) {
        device_idx = Pa_GetDefaultInputDevice();
        if (device_idx == paNoDevice) {
            std::cerr << "é”™è¯¯ï¼šæ²¡æœ‰é»˜è®¤è¾“å…¥è®¾å¤‡ï¼Œå°†ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨è®¾å¤‡ã€‚" << std::endl;
            device_idx = devices[0].index;
        }
    }

    PaStreamParameters input_parameters;
    input_parameters.device = device_idx;
    input_parameters.channelCount = 1;
    input_parameters.sampleFormat = paFloat32;
    input_parameters.suggestedLatency = 0.1;
    input_parameters.hostApiSpecificStreamInfo = nullptr;

    err = Pa_OpenStream(&audio_stream_, &input_parameters, nullptr, sample_rate_,
                        samples_per_read_, paNoFlag, nullptr, nullptr);
    if (err != paNoError) {
        std::cerr << "æ‰“å¼€éŸ³é¢‘æµå¤±è´¥: " << Pa_GetErrorText(err) << std::endl;
        Pa_Terminate();
        return;
    }

    err = Pa_StartStream(audio_stream_);
    if (err != paNoError) {
        std::cerr << "å¯åŠ¨éŸ³é¢‘æµå¤±è´¥: " << Pa_GetErrorText(err) << std::endl;
        Pa_CloseStream(audio_stream_);
        Pa_Terminate();
        return;
    }
    
    std::cout << "\næˆåŠŸæ‰“å¼€è®¾å¤‡: " << Pa_GetDeviceInfo(device_idx)->name << " (ç´¢å¼• " << device_idx << ")" << std::endl;
    std::cout << "è¯·å¼€å§‹è¯´è¯... (æŒ‰Ctrl+Cé€€å‡º)" << std::endl;
    std::cout << "--------------------------------------------------" << std::endl;

    std::vector<float> buffer(samples_per_read_);
    while (g_running) {
        err = Pa_ReadStream(audio_stream_, buffer.data(), samples_per_read_);
        if (err != paNoError) {
            std::this_thread::sleep_for(std::chrono::milliseconds(20));
            continue;
        }

        if (g_is_tts_speaking) {
            continue;
        }
        
        vad_->AcceptWaveform(buffer.data(), buffer.size());

        if (vad_->IsDetected() && !is_speech_detected_) {
            std::cout << "\nğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³..." << std::endl;
            is_speech_detected_ = true;
            last_result_.clear();
        }

        while (!vad_->IsEmpty()) {
            auto segment = vad_->Front();
            // 3. ä¿®æ­£ï¼šä½¿ç”¨ç±»æˆå‘˜å˜é‡ sample_rate_
            stream_->AcceptWaveform(sample_rate_, segment.samples.data(), segment.samples.size());
            while (recognizer_->IsReady(stream_.get())) {
                recognizer_->Decode(stream_.get());
            }
            auto result = recognizer_->GetResult(stream_.get());
            if (!result.text.empty() && result.text != last_result_) {
                last_result_ = result.text;
                std::cout << "ğŸ“ è¯†åˆ«ç»“æœ: " << result.text << std::endl;
            }
            vad_->Pop();
        }
        
        if (!vad_->IsDetected() && is_speech_detected_) {
            std::cout << "ğŸ”‡ è¯­éŸ³ç»“æŸ" << std::endl;
            is_speech_detected_ = false;
            if (!last_result_.empty()) {
                callback(last_result_);
            }
            // 3. ä¿®æ­£ unique_ptr çš„é‡æ–°èµ‹å€¼
            stream_ = std::make_unique<OnlineStream>(recognizer_->CreateStream());
        }
    }

    Pa_StopStream(audio_stream_);
    Pa_CloseStream(audio_stream_);
    Pa_Terminate();
}

// #include <iostream>
// #include <string>
// #include <vector>
// #include <chrono>
// #include <thread>
// #include <atomic>
// #include <signal.h>
// #include <fstream>
// #include <cstdlib>
// #include <memory>
// #include <portaudio.h>
// #include <sherpa-onnx/c-api/cxx-api.h>
// #include <functional>

// using namespace sherpa_onnx::cxx;

// // å…¨å±€å˜é‡ç”¨äºä¿¡å·å¤„ç†
// std::atomic<bool> g_running(true);
// // #include "audio_monitor.h"

// // ä¿¡å·å¤„ç†å‡½æ•°
// void signal_handler(int signal) {
//     if (signal == SIGINT || signal == SIGTERM) {
//         std::cout << "\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­" << std::endl;
//         g_running = false;
//     }
// }

// // éŸ³é¢‘è®¾å¤‡ä¿¡æ¯ç»“æ„
// struct AudioDevice {
//     int index;
//     std::string name;
//     bool is_input;
//     int max_input_channels;
//     int max_output_channels;
//     double default_sample_rate;
// };

// // éŸ³é¢‘ç›‘æ§å™¨ç±»
// class AudioMonitor {
// private:
//     std::string model_dir_ = "/home/lx/æ¡Œé¢/Voice/LLM_Voice_Flow-master/voice/models/sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16";
//     std::string vad_model_path_;
//     int sample_rate_;
//     int samples_per_read_;
    
//     std::unique_ptr<OnlineRecognizer> recognizer_;
//     std::unique_ptr<VoiceActivityDetector> vad_;
//     std::unique_ptr<OnlineStream> stream_;
    
//     std::atomic<bool> is_speech_detected_;
//     std::string last_result_;
    
//     // PortAudioç›¸å…³
//     PaStream* audio_stream_;
    
// public:
//     AudioMonitor(const std::string& model_dir, const std::string& vad_model_path = "")
//         // : model_dir_(model_dir)
//         : vad_model_path_(vad_model_path)
//         , sample_rate_(16000)
//         , samples_per_read_(static_cast<int>(0.1 * sample_rate_)) // 200ms
//         , is_speech_detected_(false)
//         , audio_stream_(nullptr)
//     {
//         init_models();
//     }
    
//     ~AudioMonitor() {
//         if (audio_stream_) {
//             Pa_CloseStream(audio_stream_);
//         }
//     }
    
//     // åˆå§‹åŒ–æ¨¡å‹
//     void init_models() {
//         std::cout << "æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹..." << std::endl;
        
//         // åˆå§‹åŒ–VAD
//         init_vad();
        
//         // åˆå§‹åŒ–ASR
//         init_asr();
        
//         std::cout << "æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼" << std::endl;
//     }
    
//     // åˆå§‹åŒ–VADæ¨¡å‹
//     void init_vad() {
//         if (vad_model_path_.empty()) {
//             vad_model_path_ = download_vad_model();
//         }
        
//         VadModelConfig config;
//         config.silero_vad.model = vad_model_path_;
//         config.sample_rate = sample_rate_;
//         config.silero_vad.threshold = 0.5;
//         config.silero_vad.min_speech_duration = 0.25;
//         config.silero_vad.min_silence_duration = 0.5;
//         config.silero_vad.window_size = 512;
//         config.debug = false;
        
//         vad_ = std::make_unique<VoiceActivityDetector>(VoiceActivityDetector::Create(config, 30));
//         if (!vad_->Get()) {
//             std::cerr << "é”™è¯¯ï¼šVADæ¨¡å‹åˆå§‹åŒ–å¤±è´¥" << std::endl;
//             exit(-1);
//         }
        
//         std::cout << "VADæ¨¡å‹åˆå§‹åŒ–å®Œæˆ" << std::endl;
//     }
    
//     // åˆå§‹åŒ–ASRæ¨¡å‹
//     void init_asr() {
//         OnlineRecognizerConfig config;
        
//         // æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
//         std::string encoder_path = model_dir_ + "/encoder-epoch-99-avg-1.onnx";
//         std::string decoder_path = model_dir_ + "/decoder-epoch-99-avg-1.onnx";
//         std::string joiner_path = model_dir_ + "/joiner-epoch-99-avg-1.onnx";
//         std::string tokens_path = model_dir_ + "/tokens.txt";
        
//         // å¦‚æœint8æ¨¡å‹å­˜åœ¨ï¼Œä½¿ç”¨int8æ¨¡å‹ä»¥æé«˜æ€§èƒ½
//         std::string encoder_int8_path = model_dir_ + "/encoder-epoch-99-avg-1.int8.onnx";
//         std::string decoder_int8_path = model_dir_ + "/decoder-epoch-99-avg-1.int8.onnx";
//         std::string joiner_int8_path = model_dir_ + "/joiner-epoch-99-avg-1.int8.onnx";
        
//         // æ£€æŸ¥int8æ¨¡å‹æ˜¯å¦å­˜åœ¨
//         if (file_exists(encoder_int8_path) && file_exists(decoder_int8_path) && file_exists(joiner_int8_path)) {
//             encoder_path = encoder_int8_path;
//             decoder_path = decoder_int8_path;
//             joiner_path = joiner_int8_path;
//             std::cout << "ä½¿ç”¨int8é‡åŒ–æ¨¡å‹ä»¥æé«˜æ€§èƒ½" << std::endl;
//         }
        
//         // éªŒè¯æ¨¡å‹æ–‡ä»¶
//         if (!file_exists(encoder_path) || !file_exists(decoder_path) || 
//             !file_exists(joiner_path) || !file_exists(tokens_path)) {
//             std::cerr << "é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨" << std::endl;
//             std::cerr << "è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨ï¼š" << std::endl;
//             std::cerr << "  " << encoder_path << std::endl;
//             std::cerr << "  " << decoder_path << std::endl;
//             std::cerr << "  " << joiner_path << std::endl;
//             std::cerr << "  " << tokens_path << std::endl;
//             exit(-1);
//         }
        
//         // é…ç½®è¯†åˆ«å™¨
//         config.model_config.transducer.encoder = encoder_path;
//         config.model_config.transducer.decoder = decoder_path;
//         config.model_config.transducer.joiner = joiner_path;
//         config.model_config.tokens = tokens_path;
//         config.model_config.num_threads = 4;
//         config.model_config.debug = false;
        
//         recognizer_ = std::make_unique<OnlineRecognizer>(OnlineRecognizer::Create(config));
//         if (!recognizer_->Get()) {
//             std::cerr << "é”™è¯¯ï¼šASRæ¨¡å‹åˆå§‹åŒ–å¤±è´¥" << std::endl;
//             exit(-1);
//         }
        
//         stream_ = std::make_unique<OnlineStream>(recognizer_->CreateStream());
//         std::cout << "ASRæ¨¡å‹åˆå§‹åŒ–å®Œæˆ" << std::endl;
//     }
    
//     // ä¸‹è½½VADæ¨¡å‹
//     std::string download_vad_model() {
//         std::string vad_model_path = "/home/lx/æ¡Œé¢/Voice/LLM_Voice_Flow-master/voice/models/sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16/silero_vad.onnx";
//         std::string vad_model_url = "https://github.com/snakers4/silero-vad/raw/master/src/silero_vad/data/silero_vad.onnx";
        
//         if (!file_exists(vad_model_path)) {
//             std::cout << "æ­£åœ¨ä¸‹è½½VADæ¨¡å‹..." << std::endl;
//             std::string cmd = "wget -O " + vad_model_path + " " + vad_model_url;
//             int result = system(cmd.c_str());
//             if (result != 0) {
//                 std::cerr << "ä¸‹è½½VADæ¨¡å‹å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨ä¸‹è½½silero_vad.onnxæ–‡ä»¶" << std::endl;
//                 exit(-1);
//             }
//             std::cout << "VADæ¨¡å‹ä¸‹è½½å®Œæˆ" << std::endl;
//         }
        
//         return vad_model_path;
//     }
    
//     // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
//     bool file_exists(const std::string& path) {
//         std::ifstream file(path);
//         return file.good();
//     }
    
//     // åˆ—å‡ºéŸ³é¢‘è®¾å¤‡
//     std::vector<AudioDevice> list_audio_devices() {
//         std::vector<AudioDevice> devices;
        
//         int num_devices = Pa_GetDeviceCount();
//         std::cout << "\n=== å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡ ===" << std::endl;
        
//         for (int i = 0; i < num_devices; ++i) {
//             const PaDeviceInfo* device_info = Pa_GetDeviceInfo(i);
//             if (device_info) {
//                 AudioDevice device;
//                 device.index = i;
//                 device.name = device_info->name;
//                 device.is_input = (device_info->maxInputChannels > 0);
//                 device.max_input_channels = device_info->maxInputChannels;
//                 device.max_output_channels = device_info->maxOutputChannels;
//                 device.default_sample_rate = device_info->defaultSampleRate;
                
//                 std::string device_type = device.is_input ? "è¾“å…¥" : "è¾“å‡º";
//                 std::cout << i << ": " << device.name << " (" << device_type << ")" << std::endl;
                
//                 devices.push_back(device);
//             }
//         }
        
//         int default_input = Pa_GetDefaultInputDevice();
//         if (default_input != paNoDevice) {
//             const PaDeviceInfo* default_info = Pa_GetDeviceInfo(default_input);
//             if (default_info) {
//                 std::cout << "\né»˜è®¤è¾“å…¥è®¾å¤‡: " << default_info->name << std::endl;
//             }
//         }
        
//         return devices;
//     }
    

//     // åœ¨ AudioMonitor ç±»ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹ start_monitoringï¼Œè®©å®ƒæ¥å—ä¸€ä¸ªå›è°ƒ
//     // å¼€å§‹éŸ³é¢‘ç›‘æ§
//     void start_monitoring(int device_idx, const std::function<void(const std::string&)>& callback) {
//         // 1. é¦–å…ˆï¼Œåˆå§‹åŒ– PortAudio
//         PaError err = Pa_Initialize();
//         if (err != paNoError) {
//             std::cerr << "!!! PortAudio åˆå§‹åŒ–å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯: " << Pa_GetErrorText(err) << std::endl;
//             return;
//         }

//         // 2. åˆå§‹åŒ–æˆåŠŸåï¼Œå†è·å–è®¾å¤‡åˆ—è¡¨
//         auto devices = list_audio_devices();

//         // å¦‚æœè®¾å¤‡åˆ—è¡¨ä¸ºç©ºï¼Œåˆ™æ²¡æœ‰å¯ç”¨çš„è®¾å¤‡
//         if (devices.empty()) {
//             std::cerr << "é”™è¯¯ï¼šæœªæ‰¾åˆ°ä»»ä½•éŸ³é¢‘è¾“å…¥è®¾å¤‡ã€‚" << std::endl;
//             Pa_Terminate(); // é€€å‡ºå‰ç»ˆæ­¢PortAudio
//             return;
//         }

//         // 3. å¦‚æœæœªæŒ‡å®šè®¾å¤‡ï¼Œåˆ™è·å–é»˜è®¤è¾“å…¥è®¾å¤‡
//         if (device_idx == -1) {
//             device_idx = Pa_GetDefaultInputDevice();
//             if (device_idx == paNoDevice) {
//                 std::cerr << "é”™è¯¯ï¼šæ²¡æœ‰é»˜è®¤çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡ï¼Œè¯·é€šè¿‡ --device å‚æ•°æŒ‡å®šä¸€ä¸ªã€‚" << std::endl;
//                 Pa_Terminate();
//                 return;
//             }
//         }

//         // 4. æ£€æŸ¥æœ€ç»ˆçš„è®¾å¤‡ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
//         if (device_idx >= static_cast<int>(devices.size()) || device_idx < 0) {
//             std::cerr << "é”™è¯¯ï¼šè®¾å¤‡ç´¢å¼• " << device_idx << " è¶…å‡ºèŒƒå›´ã€‚" << std::endl;
//             Pa_Terminate();
//             return;
//         }

//         // 5. é…ç½®å¹¶æ‰“å¼€æŒ‡å®šçš„éŸ³é¢‘æµ (ä½¿ç”¨ Pa_OpenStream)
//         PaStreamParameters input_parameters;
//         input_parameters.device = device_idx;
//         input_parameters.channelCount = 1;
//         input_parameters.sampleFormat = paFloat32;
//         input_parameters.suggestedLatency = 0.1; // 100ms å»¶è¿Ÿ
//         input_parameters.hostApiSpecificStreamInfo = nullptr;

//         err = Pa_OpenStream(
//             &audio_stream_,
//             &input_parameters,
//             nullptr, // æ²¡æœ‰è¾“å‡º
//             sample_rate_,
//             samples_per_read_,
//             paNoFlag,
//             nullptr,
//             nullptr
//         );

//         if (err != paNoError) {
//             std::cerr << "æ‰“å¼€éŸ³é¢‘æµå¤±è´¥: " << Pa_GetErrorText(err) << std::endl;
//             Pa_Terminate();
//             return;
//         }

//         std::string device_name = devices[device_idx].name;
//         std::cout << "\næˆåŠŸæ‰“å¼€è®¾å¤‡: " << device_name << " (ç´¢å¼• " << device_idx << ")" << std::endl;
//         std::cout << "è¯·å¼€å§‹è¯´è¯... (æŒ‰Ctrl+Cé€€å‡º)" << std::endl;
//         std::cout << "--------------------------------------------------" << std::endl;

//         // 6. å¯åŠ¨éŸ³é¢‘æµ
//         err = Pa_StartStream(audio_stream_);
//         if (err != paNoError) {
//             std::cerr << "å¯åŠ¨éŸ³é¢‘æµå¤±è´¥: " << Pa_GetErrorText(err) << std::endl;
//             Pa_CloseStream(audio_stream_);
//             Pa_Terminate();
//             return;
//         }

//         // 7. éŸ³é¢‘å¤„ç†å¾ªç¯ (ä¿æŒä¸å˜)
//         std::vector<float> buffer(samples_per_read_);
//         while (g_running) {
//             err = Pa_ReadStream(audio_stream_, buffer.data(), samples_per_read_);
//             if (err != paNoError) {
//                 std::cerr << "è¯»å–éŸ³é¢‘æ•°æ®å¤±è´¥: " << Pa_GetErrorText(err) << std::endl;
//                 break;
//             }

//             vad_->AcceptWaveform(buffer.data(), buffer.size());

//             if (vad_->IsDetected() && !is_speech_detected_) {
//                 std::cout << "\nğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³..." << std::endl;
//                 is_speech_detected_ = true;
//                 last_result_.clear();
//             }

//             while (!vad_->IsEmpty()) {
//                 auto segment = vad_->Front();
//                 stream_->AcceptWaveform(sample_rate_, segment.samples.data(), segment.samples.size());
//                 while (recognizer_->IsReady(stream_.get())) {
//                     recognizer_->Decode(stream_.get());
//                 }
//                 OnlineRecognizerResult result = recognizer_->GetResult(stream_.get());
//                 if (!result.text.empty() && result.text != last_result_) {
//                     last_result_ = result.text;
//                     std::cout << "ğŸ“ è¯†åˆ«ç»“æœ: " << result.text << std::endl;
//                 }
//                 vad_->Pop();
//             }
//             // åœ¨ AudioMonitor ç±»ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹ start_monitoringï¼Œè®©å®ƒæ¥å—ä¸€ä¸ªå›è°ƒ
//             /*#############################################################################*/
//             if (!vad_->IsDetected() && is_speech_detected_) {
//                 std::cout << "ğŸ”‡ è¯­éŸ³ç»“æŸ" << std::endl;
//                 is_speech_detected_ = false;
//                 if (!last_result_.empty()) {
//                     callback(last_result_); // è°ƒç”¨å›è°ƒå‡½æ•°
//                 }
//                 stream_ = std::make_unique<OnlineStream>(recognizer_->CreateStream());
//             }
//         }

//         // 8. æ¸…ç†èµ„æº
//         Pa_StopStream(audio_stream_);
//         Pa_CloseStream(audio_stream_);
//         Pa_Terminate();
//     }
// };

// int main(int argc, char* argv[]) {
//     // è®¾ç½®ä¿¡å·å¤„ç†
//     signal(SIGINT, signal_handler);
//     signal(SIGTERM, signal_handler);
    
//     // è§£æå‘½ä»¤è¡Œå‚æ•°
//     std::string model_dir = "models/sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16";
//     std::string vad_model_path = "";
//     int device_idx = -1;
//     bool list_devices = false;
    
//     for (int i = 1; i < argc; ++i) {
//         std::string arg = argv[i];
//         if (arg == "--model-dir" && i + 1 < argc) {
//             model_dir = argv[++i];
//         } else if (arg == "--vad-model" && i + 1 < argc) {
//             vad_model_path = argv[++i];
//         } else if (arg == "--device" && i + 1 < argc) {
//             device_idx = std::stoi(argv[++i]);
//         } else if (arg == "--list-devices") {
//             list_devices = true;
//         } else if (arg == "--help" || arg == "-h") {
//             std::cout << "éŸ³é¢‘ç›‘æ§å’Œè¯­éŸ³è½¬æ–‡æœ¬ç¨‹åº (C++ç‰ˆæœ¬)" << std::endl;
//             std::cout << "ç”¨æ³•: " << argv[0] << " [é€‰é¡¹]" << std::endl;
//             std::cout << "é€‰é¡¹:" << std::endl;
//             std::cout << "  --model-dir DIR     è¯­éŸ³è¯†åˆ«æ¨¡å‹ç›®å½•" << std::endl;
//             std::cout << "  --vad-model PATH    VADæ¨¡å‹æ–‡ä»¶è·¯å¾„" << std::endl;
//             std::cout << "  --device INDEX      éŸ³é¢‘è®¾å¤‡ç´¢å¼•" << std::endl;
//             std::cout << "  --list-devices      åˆ—å‡ºæ‰€æœ‰éŸ³é¢‘è®¾å¤‡å¹¶é€€å‡º" << std::endl;
//             std::cout << "  --help, -h          æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯" << std::endl;
//             return 0;
//         }
//     }
    
//     try {
//         // åˆ›å»ºéŸ³é¢‘ç›‘æ§å™¨
//         AudioMonitor monitor(model_dir, vad_model_path);
        
//         if (list_devices) {
//             monitor.list_audio_devices();
//             return 0;
//         }
        
//         // å¼€å§‹ç›‘æ§
//         monitor.start_monitoring(device_idx);
        
//     } catch (const std::exception& e) {
//         std::cerr << "é”™è¯¯: " << e.what() << std::endl;
//         return -1;
//     }
    
//     return 0;
// } 